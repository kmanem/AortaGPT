{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60cfd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in dir(\"/Users/aindukur/Documents/Projects/Personal/AortaGPT/data/raw\"):\n",
    "    def read_pdf(self, filename: str) -> str:\n",
    "            \"\"\"Read and return text content from a PDF file.\"\"\"\n",
    "            if filename in self.document_cache:\n",
    "                return self.document_cache[filename]\n",
    "\n",
    "            file_path = os.path.join(self.data_folder, filename)\n",
    "            if not os.path.exists(file_path):\n",
    "                logger.warning(f\"File not found: {file_path}\")\n",
    "                return \"\"\n",
    "\n",
    "            try:\n",
    "                reader = PdfReader(file_path)\n",
    "                text = \"\"\n",
    "                for page in reader.pages:\n",
    "                    page_text = page.extract_text() or \"\"\n",
    "                    text += page_text + \"\\n\\n\"\n",
    "                self.document_cache[filename] = text\n",
    "                txt_filename = f\"{name}.txt\"\n",
    "                with open(txt_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n",
    "                return text\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading PDF {filename}: {e}\")\n",
    "                return \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b4d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_embedding(text):\n",
    "    '''\n",
    "    Generate embedding for a given text\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to generate embedding for\n",
    "    Returns:\n",
    "        np.array: Embedding vector\n",
    "    '''\n",
    "    response = openai.embeddings.create(input=text, model=\"text-embedding-3-large\")\n",
    "    return np.array(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    '''\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "    \n",
    "    Args:\n",
    "        vec1 : numpy.array\n",
    "            First vector\n",
    "        vec2 : numpy.array\n",
    "            Second vector\n",
    "    \n",
    "    Returns:\n",
    "        float\n",
    "            The cosine similarity between the two vectors\n",
    "    '''\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_policy_docs(query: str, top_k: int=2) -> str:\n",
    "    \"\"\"\n",
    "    Search for company policy documents that match a query and return information from the top_k results.\n",
    "    \n",
    "    USE THIS TOOL ONLY FOR:\n",
    "    - Responding to Noncompliance with Laws and Regulations When Providing Client Services (U.S., IND, MEX & GER)\n",
    "    - Mandatory Compliance with Periodic Reporting Requirements for PPMDs, Senior Managers, and Managers (U.S., IND, CR, MEX & GER)\n",
    "    - Third Party Risk Management (U.S., IND, MEX & GER)\n",
    "    - Relocation Assistance for Employees (Other than Managing Directors) (U.S.)\n",
    "    - Artificial Intelligence (AI) Policy (U.S., IND, CR, MEX & GER)\n",
    "    - Expectations Concerning Independence Policies and Consequences of Noncompliance (U.S., IND, CR, MEX & GER)\n",
    "    - Restrictions on Procuring, Downloading, Installing, Accessing, or Copying Technology (U.S. & IND)\n",
    "    - Time Reporting\n",
    "    - Lobbying and Related Activities (U.S.)\n",
    "    - Continuing Professional Education (CPE) Compliance (U.S.)\n",
    "    - Gifts and Entertainment for U.S. Public Officials (U.S.)\n",
    "    - Information Security (U.S., IND, CR, MEX & GER)\n",
    "    - Dealing with Suppliers, Service Providers, and Contractors (U.S., IND, CR, MEX & GER)\n",
    "    - Insurance (U.S. & MEX)\n",
    "    - Laptop Security (U.S., IND, CR, MEX & GER)\n",
    "    - Mobile Devices (U.S.)\n",
    "    - Long-Term Travel and Subsistence Expenses (U.S.)\n",
    "    - Gifts and Prizes To Personnel (U.S.)\n",
    "    - Physical Security and Safety (U.S., IND, MEX & GER)\n",
    "    - Expense Reimbursement (U.S.)\n",
    "    - Entertainment (U.S.)\n",
    "    - Firm-Sponsored Activities (U.S. & IND)\n",
    "    - Donations, Political Contributions, and Sponsorships (U.S., IND & MEX)\n",
    "    - Certified Public Accountant Licensing (U.S.)\n",
    "    - Wireless Communications (U.S., IND, CR, MEX & GER)\n",
    "    - Copyright - Infringement Issues (U.S., IND, CR, MEX & GER)\n",
    "    - Mandatory Broker Data Import Program for Employees Required to Maintain a Tracking & Trading Portfolio (U.S., IND & MEX)\n",
    "    - Gifts To and From Clients (U.S.)\n",
    "    - Personal Automobile Liability Insurance Employees (U.S.)\n",
    "\n",
    "    DO NOT use this tool for technical troubleshooting or hardware/software questions - use ServiceNow_Researcher for those.\n",
    "    \n",
    "    Args:\n",
    "        query: The policy-related query to search for.\n",
    "        top_k: The number of top similar policy documents to retrieve. Default value is 2.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string containing results of the search\n",
    "    \"\"\"\n",
    "    df = pd.read_pickle(\"data/policy_pdf_embeddings.pkl\")  # Load stored embeddings\n",
    "    \n",
    "    query_embedding = generate_embedding(query)\n",
    "    \n",
    "\n",
    "    # Compute similarity for all documents\n",
    "    df[\"similarity\"] = df[\"vector\"].apply(lambda x: cosine_similarity(query_embedding, np.array(x)))\n",
    "    \n",
    "    # Sort by similarity and get the top_k results\n",
    "    top_results = df.sort_values(by=\"similarity\", ascending=False).head(top_k)\n",
    "    \n",
    "    # Check if no results were found\n",
    "    if top_results.empty:\n",
    "        return \"No similar PDFs found.\"\n",
    "    \n",
    "    # Format the response with titles in a similar way to call_snow_search()\n",
    "    result_str = \"here are the relevant documents, each document is separated by '<<<<<<<>>>>>>>>'\\n\\n\" + \"\\n<<<<<<<>>>>>>>>\\n\".join(\n",
    "        [f\"title: {row['title']}\\n\\ntext: {row['text']}\" for _, row in top_results.iterrows()]\n",
    "    ) + \"\\n<<<<<<<>>>>>>>>\"\n",
    "    \n",
    "    return result_str\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
